{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79894cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87e64a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0, 0],\n",
    "              [0, 1], \n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    "\n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1], \n",
    "              [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de3eb851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "320c2df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983c18f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dC_da(a, y_true):\n",
    "    return 2*(a- y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ea45e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def da_dz(z):\n",
    "    return sigmoid(z) * (1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0feaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, input_size: int, neuron_count: int):\n",
    "        self.W = np.random.randn(input_size, neuron_count) * 0.1\n",
    "        self.b = np.zeros((1, neuron_count))\n",
    "        \n",
    "        self.inputs = np.array([])\n",
    "        self.activations = np.array([])\n",
    "        \n",
    "    def forward(self, X: np.ndarray):   \n",
    "        self.inputs = X\n",
    "        z = X @ self.W + self.b\n",
    "        a = sigmoid(z)\n",
    "        self.activations = a\n",
    "        return a\n",
    "    \n",
    "    def backward(self, delta, is_output, learning_rate):\n",
    "        dz = np.array([])\n",
    "        \n",
    "        if is_output:\n",
    "            dz = delta\n",
    "        else:\n",
    "            dz = delta * da_dz(self.activations)\n",
    "        \n",
    "        dW = self.inputs.T @ dz\n",
    "        db = np.sum(dz)\n",
    "        \n",
    "        delta_prev = dz @ self.W\n",
    "        \n",
    "        self.W -= learning_rate * dW\n",
    "        self.b -= learning_rate * db\n",
    "        \n",
    "        return delta_prev\n",
    "    \n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2049768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       , 0.5       ],\n",
       "       [0.49666075, 0.51127895, 0.46706556],\n",
       "       [0.46969529, 0.51866384, 0.4835022 ],\n",
       "       [0.46636966, 0.52991761, 0.45067496]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = Layer(input_size=2, neuron_count=3)\n",
    "layer.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac5a70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49962911]\n",
      " [0.49925685]\n",
      " [0.50005627]\n",
      " [0.49968249]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.24999981854739867)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "class Network:\n",
    "    def __init__(self, layers: List[Layer]):\n",
    "        self.layers = layers\n",
    "    \n",
    "    def forward(self, X: np.ndarray):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "        return X\n",
    "\n",
    "    def backwards(self, X, y_true):\n",
    "                \n",
    "        weight_grad = np.array([])\n",
    "        \n",
    "    \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "layer1 = Layer(input_size=2, neuron_count=3)\n",
    "layer2 = Layer(input_size=3, neuron_count=1)\n",
    "layers = [layer1, layer2]\n",
    "network = Network(layers)\n",
    "\n",
    "y_pred = network.forward(X)\n",
    "print(y_pred)\n",
    "MSE(y, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
